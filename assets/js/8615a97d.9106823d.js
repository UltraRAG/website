"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[656],{618(e,n,t){t.d(n,{En:()=>s,Zh:()=>a});t(6540);var r=t(6666),i=t(4848);function s({children:e}){const{lang:n}=(0,r.o)();return"en"!==n?null:(0,i.jsx)(i.Fragment,{children:e})}function a({children:e}){const{lang:n}=(0,r.o)();return"zh"!==n?null:(0,i.jsx)(i.Fragment,{children:e})}},1307(e){e.exports=JSON.parse('{"permalink":"/blog/ultrarag-2.1-release","source":"@site/blog/2025-11-11-ultrarag-2.1-release.md","title":"UltraRAG 2.1: Deep Knowledge Integration, Cross-Modal Support","description":"In the process of building knowledge bases, setting up experimental systems, and evaluating results, researchers always encounter similar challenges: How to achieve multimodal retrieval and generation within a unified framework? How to efficiently integrate multi-source knowledge? And how to make complex RAG experiments easier to build and reproduce?","date":"2025-11-11T00:00:00.000Z","tags":[{"inline":false,"label":"Release","permalink":"/blog/tags/release","description":"UltraRAG release announcements"},{"inline":false,"label":"UltraRAG","permalink":"/blog/tags/ultrarag","description":"UltraRAG related posts"}],"readingTime":9.49,"hasTruncateMarker":true,"authors":[{"name":"Sen Mei","title":"TsinghuaNLP","url":"https://mssssss123.github.io/","imageURL":"/img/team/ms.png","key":"ms","page":null},{"name":"Haidong Xin","title":"NEUIR","url":"https://xinhaidong.top/","imageURL":"/img/team/xhd.jpg","key":"xhd","page":null}],"frontMatter":{"slug":"ultrarag-2.1-release","title":"UltraRAG 2.1: Deep Knowledge Integration, Cross-Modal Support","authors":["ms","xhd"],"tags":["release","ultrarag"],"date":"2025-11-11T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"UltraRAG 3.0: No More Black Boxes, Full Transparency in Reasoning","permalink":"/blog/ultrarag-3.0-release"},"nextItem":{"title":"UltraRAG 2.0: Minimal Code, Maximum Innovation","permalink":"/blog/ultrarag-2.0-release"}}')},7158(e,n,t){t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>g,frontMatter:()=>o,metadata:()=>r,toc:()=>c});var r=t(1307),i=t(4848),s=t(8453),a=t(618);const o={slug:"ultrarag-2.1-release",title:"UltraRAG 2.1: Deep Knowledge Integration, Cross-Modal Support",authors:["ms","xhd"],tags:["release","ultrarag"],date:new Date("2025-11-11T00:00:00.000Z")},l=void 0,d={authorsImageUrls:[void 0,void 0]},c=[{value:"Native Multimodal Support",id:"native-multimodal-support",level:2},{value:"Automated Knowledge Integration &amp; Corpus Construction",id:"automated-knowledge-integration--corpus-construction",level:2},{value:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301",id:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301",level:2},{value:"\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316",id:"\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316",level:2}];function u(e){const n={h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(a.En,{children:[(0,i.jsx)(n.p,{children:"In the process of building knowledge bases, setting up experimental systems, and evaluating results, researchers always encounter similar challenges: How to achieve multimodal retrieval and generation within a unified framework? How to efficiently integrate multi-source knowledge? And how to make complex RAG experiments easier to build and reproduce?"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1"})," addresses these research challenges with comprehensive upgrades focused on practical needs. This update brings core enhancements in three directions: ",(0,i.jsx)(n.strong,{children:"native multimodal support, automated knowledge integration and corpus construction, and unified build-and-evaluate RAG workflows"}),":"]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Native Multimodal Support"}),": Unified Retriever, Generation, and Evaluation modules with full multimodal retrieval and generation support; new ",(0,i.jsx)(n.strong,{children:"VisRAG Pipeline"})," enabling a complete closed-loop from local PDF indexing to multimodal retrieval and generation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automated Knowledge Integration & Corpus Construction"}),": Supports multi-format document parsing and chunked indexing, seamlessly integrating MinerU for easy construction of personalized knowledge bases."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unified Build & Evaluate RAG Workflows"}),": Compatible with multiple retrieval and generation inference engines, providing a standardized evaluation system with full-chain visual analysis, achieving a unified process from model invocation to result verification."]}),"\n"]}),(0,i.jsx)(n.h2,{id:"native-multimodal-support",children:"Native Multimodal Support"}),(0,i.jsx)(n.p,{children:"Previously, multimodal RAG often relied on multiple independent tools: text tasks and visual tasks belonged to different workflows, requiring researchers to switch between feature extraction, retrieval, generation, and evaluation tools, with inconsistent interfaces and difficult reproducibility."}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1"})," systematically integrates the multimodal RAG pipeline. All core Servers \u2014 ",(0,i.jsx)(n.strong,{children:"Retriever, Generation, and Evaluation"})," \u2014 now natively support multimodal tasks and can flexibly connect to various visual, text, or cross-modal models. Researchers can freely orchestrate their own multimodal pipelines within the unified framework \u2014 whether for document QA, image-text retrieval, or cross-modal generation \u2014 all achievable with minimal effort for end-to-end integration. Additionally, the framework's built-in ",(0,i.jsx)(n.strong,{children:"Benchmarks"})," cover various tasks including visual QA, with a unified evaluation system for researchers to quickly conduct and compare multimodal experiments."]}),(0,i.jsxs)(n.p,{children:["Building on this, ",(0,i.jsx)(n.strong,{children:"UltraRAG 2.1 introduces the VisRAG Pipeline"}),', enabling a complete closed-loop from local PDF indexing to multimodal retrieval and generation. This feature is based on the research in "VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents," which proposes a vision-enhanced retrieval-augmented generation framework for multimodal documents. By jointly modeling document image information (such as charts, formulas, layout structures) with text content, it significantly improves content understanding and QA capabilities for complex scientific documents. UltraRAG integrates this approach, enabling researchers to reproduce VisRAG experiments directly on real PDF document scenarios and further extend multimodal retrieval-generation research and applications.']}),(0,i.jsx)(n.h2,{id:"automated-knowledge-integration--corpus-construction",children:"Automated Knowledge Integration & Corpus Construction"}),(0,i.jsx)(n.p,{children:"During RAG development, developers need to repeatedly parse, clean, and chunk materials from different sources. As a result, the RAG construction process is often slowed by trivial engineering details, compressing the space for research innovation."}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1's"})," ",(0,i.jsx)(n.strong,{children:"Corpus Server"})," makes all of this simple. Users can import corpora from different sources in one go without writing complex scripts \u2014 whether Word documents, e-books, or web archives \u2014 all automatically parsed into a unified text format. For PDF parsing, UltraRAG seamlessly integrates ",(0,i.jsx)(n.strong,{children:"MinerU"}),", accurately recognizing complex layouts and multi-column structures for high-fidelity text restoration. For mixed image-text files, it also supports converting PDFs page-by-page to images, making visual layouts part of the knowledge. For chunking strategies, ",(0,i.jsx)(n.strong,{children:"Corpus Server"})," offers multi-granularity options: supporting token-level, sentence-level, and custom rules, enabling fine-grained control of semantic boundaries while naturally adapting to structured text like Markdown."]})]}),"\n",(0,i.jsxs)(a.Zh,{children:[(0,i.jsx)(n.p,{children:"\u5728\u7814\u7a76\u8005\u6784\u5efa\u77e5\u8bc6\u5e93\u3001\u642d\u5efa\u5b9e\u9a8c\u7cfb\u7edf\u3001\u8bc4\u4f30\u5b9e\u9a8c\u7ed3\u679c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u603b\u4f1a\u9047\u5230\u76f8\u4f3c\u7684\u6311\u6218\uff1a\u5982\u4f55\u5728\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u4e2d\u5b9e\u73b0\u591a\u6a21\u6001\u68c0\u7d22\u4e0e\u751f\u6210\uff1f\u5982\u4f55\u9ad8\u6548\u63a5\u5165\u591a\u6e90\u77e5\u8bc6\uff1f\u53c8\u5982\u4f55\u8ba9\u590d\u6742\u7684 RAG \u5b9e\u9a8c\u66f4\u6613\u642d\u5efa\u3001\u66f4\u6613\u590d\u73b0\uff1f"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1"})," \u5728\u8fd9\u4e9b\u79d1\u7814\u6311\u6218\u7684\u80cc\u666f\u4e0b\uff0c\u8fdb\u884c\u4e86\u9762\u5411\u5b9e\u9645\u7814\u7a76\u9700\u6c42\u7684\u5168\u9762\u5347\u7ea7\u3002\u672c\u6b21\u66f4\u65b0\u56f4\u7ed5 ",(0,i.jsx)(n.strong,{children:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301\u3001\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316\u3001\u7edf\u4e00\u6784\u5efa\u4e0e\u8bc4\u4f30\u7684 RAG \u5de5\u4f5c\u6d41"})," \u4e09\u5927\u65b9\u5411\u5e26\u6765\u4e86\u6838\u5fc3\u589e\u5f3a\uff1a"]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301"}),"\uff1a\u7edf\u4e00 Retriever\u3001Generation \u4e0e Evaluation \u6a21\u5757\uff0c\u5168\u9762\u652f\u6301\u591a\u6a21\u6001\u68c0\u7d22\u4e0e\u751f\u6210\uff1b\u65b0\u589e ",(0,i.jsx)(n.strong,{children:"VisRAG Pipeline"}),"\uff0c\u5b9e\u73b0\u4ece\u672c\u5730 PDF \u5efa\u5e93\u5230\u591a\u6a21\u6001\u68c0\u7d22\u4e0e\u751f\u6210\u7684\u5b8c\u6574\u95ed\u73af\u3002"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316"}),"\uff1a\u652f\u6301\u591a\u683c\u5f0f\u6587\u6863\u89e3\u6790\u4e0e\u5206\u5757\u5efa\u5e93\uff0c\u65e0\u7f1d\u96c6\u6210 MinerU\uff0c\u8f7b\u677e\u6784\u5efa\u4e2a\u4eba\u5316\u77e5\u8bc6\u5e93\u3002"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u7edf\u4e00\u6784\u5efa\u4e0e\u8bc4\u4f30\u7684 RAG \u5de5\u4f5c\u6d41"}),"\uff1a\u9002\u914d\u591a\u79cd\u68c0\u7d22\u4e0e\u751f\u6210\u63a8\u7406\u5f15\u64ce\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u652f\u6301\u5168\u94fe\u8def\u53ef\u89c6\u5316\u5206\u6790\uff0c\u5b9e\u73b0\u4ece\u6a21\u578b\u8c03\u7528\u5230\u7ed3\u679c\u9a8c\u8bc1\u7684\u7edf\u4e00\u6d41\u7a0b\u3002"]}),"\n"]}),(0,i.jsx)(n.h2,{id:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301",children:"\u539f\u751f\u591a\u6a21\u6001\u652f\u6301"}),(0,i.jsx)(n.p,{children:"\u8fc7\u53bb\uff0c\u591a\u6a21\u6001 RAG \u5f80\u5f80\u9700\u8981\u4f9d\u8d56\u591a\u5957\u72ec\u7acb\u5de5\u5177\uff1a\u6587\u672c\u4efb\u52a1\u4e0e\u89c6\u89c9\u4efb\u52a1\u5206\u5c5e\u4e0d\u540c\u6d41\u7a0b\uff0c\u7814\u7a76\u8005\u9700\u5728\u7279\u5f81\u63d0\u53d6\u3001\u68c0\u7d22\u3001\u751f\u6210\u548c\u8bc4\u4f30\u5de5\u5177\u95f4\u6765\u56de\u5207\u6362\uff0c\u63a5\u53e3\u4e0d\u7edf\u4e00\u3001\u590d\u73b0\u56f0\u96be\u3002"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1"})," \u5bf9\u591a\u6a21\u6001 RAG \u6d41\u7a0b\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u6574\u5408\u3002\u6240\u6709\u6838\u5fc3 Server\u2014\u2014",(0,i.jsx)(n.strong,{children:"Retriever\u3001Generation \u4e0e Evaluation"}),"\u2014\u2014\u5747\u5df2\u539f\u751f\u652f\u6301\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u53ef\u7075\u6d3b\u63a5\u5165\u5404\u79cd\u89c6\u89c9\u3001\u6587\u672c\u3001\u6216\u8de8\u6a21\u6001\u6a21\u578b\u3002\u7814\u7a76\u8005\u53ef\u5728\u7edf\u4e00\u6846\u67b6\u5185\u81ea\u7531\u7f16\u6392\u5c5e\u4e8e\u81ea\u5df1\u7684\u591a\u6a21\u6001 pipeline\uff0c\u65e0\u8bba\u662f\u6587\u6863\u95ee\u7b54\u3001\u56fe\u6587\u68c0\u7d22\uff0c\u8fd8\u662f\u8de8\u6a21\u6001\u751f\u6210\uff0c\u90fd\u80fd\u4ee5\u6700\u5c0f\u4ee3\u4ef7\u5b9e\u73b0\u7aef\u5230\u7aef\u8054\u901a\u3002\u6b64\u5916\uff0c\u6846\u67b6\u5185\u7f6e\u7684 ",(0,i.jsx)(n.strong,{children:"Benchmark"})," \u8986\u76d6\u89c6\u89c9\u95ee\u7b54\u7b49\u591a\u79cd\u4efb\u52a1\uff0c\u5e76\u63d0\u4f9b\u7edf\u4e00\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u65b9\u4fbf\u7814\u7a76\u8005\u5feb\u901f\u5f00\u5c55\u548c\u5bf9\u6bd4\u591a\u6a21\u6001\u5b9e\u9a8c\u3002"]}),(0,i.jsxs)(n.p,{children:["\u5728\u6b64\u57fa\u7840\u4e0a\uff0c",(0,i.jsx)(n.strong,{children:"UltraRAG 2.1 \u5f15\u5165 VisRAG Pipeline"}),"\uff0c\u5b9e\u73b0\u4ece\u672c\u5730 PDF \u5efa\u5e93\u5230\u591a\u6a21\u6001\u68c0\u7d22\u4e0e\u751f\u6210\u7684\u5b8c\u6574\u95ed\u73af\u3002\u8be5\u529f\u80fd\u57fa\u4e8e\u8bba\u6587\u300aVisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents\u300b\u7684\u7814\u7a76\u6210\u679c\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u591a\u6a21\u6001\u6587\u6863\u7684\u89c6\u89c9\u589e\u5f3a\u68c0\u7d22\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6587\u6863\u56fe\u50cf\u4fe1\u606f\uff08\u5982\u56fe\u8868\u3001\u516c\u5f0f\u3001\u7248\u9762\u7ed3\u6784\uff09\u4e0e\u6587\u672c\u5185\u5bb9\u8054\u5408\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u79d1\u5b66\u6587\u6863\u4e2d\u7684\u5185\u5bb9\u7406\u89e3\u4e0e\u95ee\u7b54\u80fd\u529b\u3002UltraRAG \u5c06\u8fd9\u4e00\u65b9\u6cd5\u96c6\u6210\uff0c\u4f7f\u7814\u7a76\u8005\u80fd\u591f\u76f4\u63a5\u5728\u771f\u5b9e PDF \u6587\u6863\u573a\u666f\u4e2d\u590d\u73b0 VisRAG \u7684\u5b9e\u9a8c\u8fc7\u7a0b\uff0c\u5e76\u8fdb\u4e00\u6b65\u6269\u5c55\u591a\u6a21\u6001\u68c0\u7d22\u751f\u6210\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u3002"]}),(0,i.jsx)(n.h2,{id:"\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316",children:"\u77e5\u8bc6\u63a5\u5165\u4e0e\u8bed\u6599\u6784\u5efa\u81ea\u52a8\u5316"}),(0,i.jsx)(n.p,{children:"\u5728 RAG \u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9762\u5bf9\u4e0d\u540c\u6765\u6e90\u7684\u8d44\u6599\uff0c\u5f00\u53d1\u8005\u9700\u8981\u53cd\u590d\u89e3\u6790\u3001\u6e05\u6d17\u3001\u5206\u5757\u3002\u7ed3\u679c\u662f\uff0cRAG \u7684\u6784\u5efa\u8fc7\u7a0b\u5f80\u5f80\u88ab\u7410\u788e\u7684\u5de5\u7a0b\u7ec6\u8282\u62d6\u6162\uff0c\u79d1\u7814\u521b\u65b0\u7684\u7a7a\u95f4\u53cd\u800c\u88ab\u538b\u7f29\u3002"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"UltraRAG 2.1"})," \u7684 ",(0,i.jsx)(n.strong,{children:"Corpus Server"})," \u8ba9\u8fd9\u4e00\u5207\u53d8\u5f97\u7b80\u5355\u3002\u7528\u6237\u65e0\u9700\u7f16\u5199\u590d\u6742\u811a\u672c\uff0c\u5c31\u80fd\u4e00\u6b21\u6027\u5bfc\u5165\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u8bed\u6599\u2014\u2014\u65e0\u8bba\u662f word \u6587\u6863\u8fd8\u662f\u7535\u5b50\u4e66\u4e0e\u7f51\u9875\u5b58\u6863\uff0c\u90fd\u80fd\u88ab\u81ea\u52a8\u89e3\u6790\u4e3a\u7edf\u4e00\u7684\u6587\u672c\u683c\u5f0f\u3002\u5728 PDF \u89e3\u6790\u65b9\u9762\uff0cUltraRAG \u65e0\u7f1d\u96c6\u6210 ",(0,i.jsx)(n.strong,{children:"MinerU"}),"\uff0c\u80fd\u591f\u7cbe\u786e\u8bc6\u522b\u590d\u6742\u7248\u9762\u4e0e\u591a\u680f\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6587\u672c\u8fd8\u539f\u3002\u5bf9\u4e8e\u56fe\u6587\u6df7\u6392\u6587\u4ef6\uff0c\u8fd8\u652f\u6301\u5c06 PDF \u6309\u9875\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u8ba9\u89c6\u89c9\u5e03\u5c40\u4e5f\u80fd\u6210\u4e3a\u77e5\u8bc6\u7684\u4e00\u90e8\u5206\u3002\u5728\u5206\u5757\u7b56\u7565\u4e0a\uff0c",(0,i.jsx)(n.strong,{children:"Corpus Server"})," \u63d0\u4f9b\u4e86\u591a\u7c92\u5ea6\u9009\u62e9\uff1a\u652f\u6301\u8bcd\u5143\u7ea7\u3001\u53e5\u5b50\u7ea7\u4e0e\u81ea\u5b9a\u4e49\u89c4\u5219\uff0c\u65e2\u80fd\u7cbe\u7ec6\u63a7\u5236\u8bed\u4e49\u8fb9\u754c\uff0c\u53c8\u80fd\u81ea\u7136\u9002\u914d Markdown \u7b49\u7ed3\u6784\u5316\u6587\u672c\u3002"]})]})]})}function g(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var r=t(6540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);